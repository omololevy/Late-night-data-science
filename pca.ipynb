{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1b278ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the system with the necessary imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bef1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the matplotlib defaults\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large', titleweight='bold',titlesize=14, titlepad=10,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3e9640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting each function it its own cell makes code a lot more cleaner and debugging easier\n",
    "# forgive me when you see me do this :)\n",
    "\n",
    "def apply_pca(X, standardize=True):\n",
    "    \n",
    "    if standardize:\n",
    "        X = (X - X.mean(axis=0)) /X.std(axis=0)\n",
    "        \n",
    "    # to create principal components\n",
    "    pca = PCA()\n",
    "    X_pca =pca.fit_transform(X)\n",
    "    \n",
    "    # to convert to dataframe\n",
    "    components_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    X_pca = pd.DataFrame(X_pca, columns=components_names)\n",
    "\n",
    "    #create loadings\n",
    "    loadings = pd.DataFrame(pca.components_.T,\n",
    "                            columns=components_names,\n",
    "                            index=X.columns,\n",
    "                            )\n",
    "    return pca, X_pca, loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b7d31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variance(pca, width=8, dpi=100):\n",
    "    # Create figure\n",
    "    fig, axs = plt.subplot(1,2)\n",
    "    n = pca.n_components_\n",
    "    grid = np.arange(1, n+1)\n",
    "\n",
    "    # Explained variance\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    axs[0].bar(grid,evr)\n",
    "    axs[0].set(\n",
    "        xlabel='Component', title= '% Explained Variance', ylim=(0.0, 1.0)\n",
    "    )\n",
    "\n",
    "    # Cumulative Variance\n",
    "    cv = np.cumsum(evr)\n",
    "    axs[1].plot(np.r_[0,grid], np.r_[0, cv], 'o-')\n",
    "    axs[1].set(\n",
    "        xlabel ='Component', title='% Cumulative Variance', ylim=(0.0, 1.0)\n",
    "    )\n",
    "\n",
    "    # Set up figure\n",
    "    fig.set(figwidth=8, dpi=100)\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14d76cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes(['object', 'category']):\n",
    "        X[colname],  _ = X[colname].factorize()\n",
    "\n",
    "    # All discrete features should now have integers dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name='MI Scores', index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "542c60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    # Label encoding for categoricals\n",
    "    for colname in X.select_dtypes(['category', 'object']):\n",
    "        X[colname], _= X[colname].factorize()\n",
    "\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    score = cross_val_score(\n",
    "        model, X, y, cv =5, scoring='neg_mean_squared_log_error', \n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f9b5bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            MSSubClass  ... SalePrice\n",
      "0  One_Story_1946_and_Newer_All_Styles  ...    215000\n",
      "1  One_Story_1946_and_Newer_All_Styles  ...    105000\n",
      "2  One_Story_1946_and_Newer_All_Styles  ...    172000\n",
      "\n",
      "[3 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing the csv file\n",
    "df =  pd.read_csv('./input/data/ames.csv')\n",
    "print(df[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b81c0b2",
   "metadata": {},
   "source": [
    "#### From the above, you notice we have a lot of features.\n",
    "Let's choose a few that are highly correlating with our target, `SalePrice` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f7213a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with SalesPrice:\n",
      "\n",
      "GarageArea      0.640138\n",
      "YearRemodAdd    0.532974\n",
      "TotalBsmtSF     0.632529\n",
      "GrLivArea       0.706780\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'GarageArea',\n",
    "    'YearRemodAdd',\n",
    "    'TotalBsmtSF',\n",
    "    'GrLivArea',\n",
    "]\n",
    "print('Correlation with SalesPrice:\\n')\n",
    "print(df[features].corrwith(df.SalePrice))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "399c1b1d",
   "metadata": {},
   "source": [
    "We'll rely on PCA to untangle the correlational structure of these features and suggest relationships that might be usefully modeled with new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d6ed158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   PC1       PC2       PC3       PC4\n",
      "GarageArea    0.541229  0.102375 -0.038470  0.833733\n",
      "YearRemodAdd  0.427077 -0.886612 -0.049062 -0.170639\n",
      "TotalBsmtSF   0.510076  0.360778 -0.666836 -0.406192\n",
      "GrLivArea     0.514294  0.270700  0.742592 -0.332837\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop('SalePrice')\n",
    "X = X.loc[:, features]\n",
    "\n",
    "# applying pca\n",
    "pca, X_pca, loadings = apply_pca(X)\n",
    "print(loadings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ac0d9b3",
   "metadata": {},
   "source": [
    "\n",
    "# 1) Interpret the Component Loadings\n",
    "Considering the loadings of component  `PC1` and `PC3`, `PC1` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
